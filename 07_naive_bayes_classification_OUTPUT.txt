Loading data with topics...
Dataset size: 530546

Original sentiment distribution:
sentiment
positive    367721
negative    116231
neutral      46594
Name: count, dtype: int64

Percentages:
sentiment
positive    69.309918
negative    21.907808
neutral      8.782273
Name: proportion, dtype: float64

Creating TF-IDF features...
Combining TF-IDF and topic features...
Feature shape: (530546, 5015)

Splitting data...
Training set: 424436 samples
Test set: 106110 samples

Training set distribution:
sentiment
positive    294176
negative     92985
neutral      37275
Name: count, dtype: int64

======================================================================
APPLYING SMOTE + UNDERSAMPLING FOR CLASS BALANCE
======================================================================

Target distribution after resampling:
  Positive: 150,000
  Negative: 100,000
  Neutral: 80,000
  Total: 330,000

Applying SMOTE to minority classes...
After SMOTE:
sentiment
positive    294176
negative    100000
neutral      80000
Name: count, dtype: int64

Applying undersampling to majority class...

Final balanced training set:
sentiment
positive    150000
negative    100000
neutral      80000
Name: count, dtype: int64
Total training samples: 330,000

======================================================================
TRAINING NAIVE BAYES MODELS (ON BALANCED DATA)
======================================================================

Training MultinomialNB...
  Accuracy: 0.8114
  Weighted F1: 0.8144

Training ComplementNB...
  Accuracy: 0.7989
  Weighted F1: 0.8046

>>> Best performing model: MultinomialNB
    F1 Score: 0.8144

======================================================================
HYPERPARAMETER TUNING: MultinomialNB
======================================================================

Performing grid search with 5-fold CV...
Fitting 5 folds for each of 14 candidates, totalling 70 fits

Best parameters: {'alpha': 0.01, 'fit_prior': False}
Best CV F1 score: 0.7279

======================================================================
EVALUATION: MultinomialNB (Tuned + Balanced Data)
======================================================================

Overall Performance:
  Accuracy: 0.7399
  Weighted F1: 0.7767

Detailed Classification Report:
              precision    recall  f1-score   support

    negative     0.7436    0.6813    0.7111     23246
     neutral     0.2290    0.6111    0.3331      9319
    positive     0.9506    0.7747    0.8537     73545

    accuracy                         0.7399    106110
   macro avg     0.6410    0.6890    0.6326    106110
weighted avg     0.8419    0.7399    0.7767    106110


======================================================================
COMPARISON: Before vs After SMOTE
======================================================================

BEFORE SMOTE (Imbalanced Data):
              precision    recall  f1-score   support

    negative     0.8057    0.6259    0.7045     23246
     neutral     0.4986    0.0190    0.0366      9319
    positive     0.8224    0.9807    0.8946     73545

    accuracy                         0.8185    106110
   macro avg     0.7089    0.5419    0.5452    106110
weighted avg     0.7903    0.8185    0.7776    106110


AFTER SMOTE (Balanced Data):
              precision    recall  f1-score   support

    negative     0.7436    0.6813    0.7111     23246
     neutral     0.2290    0.6111    0.3331      9319
    positive     0.9506    0.7747    0.8537     73545

    accuracy                         0.7399    106110
   macro avg     0.6410    0.6890    0.6326    106110
weighted avg     0.8419    0.7399    0.7767    106110


======================================================================
PER-CLASS IMPROVEMENT
======================================================================

    Class  F1_Before  F1_After  F1_Improvement  Recall_Before  Recall_After  Recall_Improvement
Negative   0.704515  0.711085        0.006570       0.625914      0.681322            0.055407
 Neutral   0.036593  0.333109        0.296516       0.018993      0.611117            0.592124
Positive   0.894624  0.853695       -0.040929       0.980692      0.774709           -0.205983

======================================================================
GENERATING VISUALIZATIONS
======================================================================

âœ“ Saved: confusion_matrix_comparison.png
âœ“ Saved: f1_score_comparison.png

======================================================================
SAVING MODELS AND RESULTS
======================================================================

âœ“ Models saved:
  - naive_bayes_model_balanced.pkl
  - tfidf_vectorizer.pkl
âœ“ Predictions saved: all_beauty_predictions_balanced.csv
âœ“ Report saved: smote_improvement_report.txt

======================================================================
SMOTE BALANCING COMPLETE!
======================================================================

ðŸŽ¯ Key Improvements:
   Neutral F1: 0.0366 â†’ 0.3331 (+0.2965)
   Neutral Recall: 0.0190 â†’ 0.6111 (+0.5921)
